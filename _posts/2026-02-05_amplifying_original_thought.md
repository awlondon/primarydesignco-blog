---
layout: post
title: "Amplifying Original Thought in an AGI Economy"
author: Alexander Warren London
published_at: 2026-02-05T09:00:00-08:00
tags: [agi, creativity, anomaly-detection, education, post-labor]
reading_time: 18
abstract: |
  Large language models do not originate ideas; they contextualize human input.
  This essay argues that the economic role of humans in an AGI economy is not
  output production but originality generation—and that anomaly detection is
  the missing interface.
---

ADE placeholder (top of post)

Anomaly Detection Engine (ADE)
Type your hypothesis or idea.

This interface evaluates predictability, not truth. It decomposes your input, positions each component against existing knowledge, and estimates where—if anywhere—your thinking departs meaningfully from prior art. Outputs include an originality score, partial originality flags, and cited lineages for derivative components.

<!-- ADE embed goes here -->

{% include ad.html %}

(Implementation follows later in the post.)

## Thirty Minutes of Thinking as Signal

This essay was produced from roughly thirty minutes of concentrated, uninterrupted thought. That fact matters more than the word count that follows.

In an AGI-saturated environment, outputs are no longer scarce. Summaries, explanations, and derivative prose can be generated on demand at near-zero marginal cost. What remains scarce is non-derivative cognition: the act of forming a hypothesis that meaningfully departs from prior formulations while remaining coherent enough to test, extend, or falsify.

From an economic perspective, those thirty minutes are not valued by time, but by leverage.

If a single concentrated thinking session produces:

a defensible conceptual distinction (originality vs. derivation),

a reframing of human–AGI roles,

and a designable interface concept (the ADE),

then its value is not comparable to wage labor or content production. It is comparable to early-stage research, product definition, or hypothesis generation—activities whose downstream value routinely compounds by orders of magnitude.

A conservative way to price this:

Comparable human labor: senior research, strategy, or product-definition work often clears $150–$300/hour.

Thirty minutes, at that rate, is $75–$150 if the output is consumed once.

But this output is not consumed once. It is:

- reusable,

- refinable,

- and amplifiable by AGI across audiences and contexts.

When an idea becomes a template for further reasoning, its expected value shifts from hourly compensation to option value. Even if only a small fraction of such ideas mature into tools, products, or research directions, the expected value of the originating cognitive act can plausibly reach thousands to tens of thousands of dollars over time.

The critical point is not the exact number. It is this:
in an AGI economy, the unit of value is not output, but original signal. Thirty minutes of genuine thinking can dominate weeks of derivative production.

What LLMs Actually Do (and Don’t)

Large language models do not discover new knowledge. They do not form hypotheses in the scientific or philosophical sense, and they do not generate originality ex nihilo.

What they do—exceptionally well—is position user input against a vast, compressed representation of prior human knowledge. When a person provides an idea, the model:

decomposes it into latent components,

maps those components onto existing patterns,

and estimates their likelihood, coherence, and adjacency.

This is why LLMs feel “creative” while remaining fundamentally derivative. They are mirrors with context: they reflect your input, but surrounded by everything that has been said before.

Crucially, this also means LLMs are excellent detectors of non-originality. They can identify when an idea closely tracks established formulations, when it recombines familiar components, and when it departs from known trajectories in ways that are statistically or conceptually unusual.

That capability is often misinterpreted. The model is not having the original thought. It is recognizing that the human has produced something anomalous relative to the corpus.

This distinction matters because it defines the correct division of labor in an AGI economy:

Humans supply anomaly, intuition, value judgments, and conceptual risk.

AGI supplies context, compression, verification scaffolding, and amplification.

When AGI is treated as a replacement for human thinking, it collapses into derivative output engines. When it is treated as an evaluator and amplifier of human originality, it becomes a force multiplier for cognition.

The Anomaly Detection Engine proposed in this essay formalizes that relationship. It does not ask AGI to be creative. It asks AGI to recognize when a human is being creative, and to explain why.

{% include ad.html %}

## What LLMs Actually Do

## Originality as Anomaly

{% include ad.html %}

## The Anomaly Detection Engine

<!-- SVG diagrams -->

{% include ad.html %}

## Why Humans Don’t Become Irrelevant

## Education Without Debt Traps

{% include ad.html %}

## Early Signals and Case Examples

## Conclusion: A Creative Cognition Economy

## References
